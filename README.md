# retail-pyspark-capstone
# ğŸ›ï¸ Retail Sales Analytics Capstone Project (PySpark + Databricks)

## ğŸ“Œ Overview

This project simulates a real-time retail sales analytics pipeline using PySpark in Databricks Community Edition. It demonstrates how raw CSV data is transformed into enriched, query-optimized Delta tables for business insights and potential Power BI integration.

## ğŸ§° Tech Stack

- ğŸ§  Apache Spark (PySpark)
- ğŸ’¾ Delta Lake
- â˜ï¸ Databricks Community Edition
- ğŸ“Š Optional: Power BI for reporting

---

## ğŸ“ Dataset Overview

The dataset is a simulated retail daily sales log with the following schema:

| Column     | Type         | Description                        |
| ---------- | ------------ | ---------------------------------- |
| sale_date  | DATE         | Date of the sale                   |
| quantity   | INT          | Units sold                         |
| stock      | INT          | Remaining inventory                |
| price      | DECIMAL(5,2) | Unit price of the product          |

Source: Uploaded manually to Databricks DBFS.

---

## ğŸ§± Data Pipeline Architecture

### ğŸŸ« Bronze Layer
- Raw CSV data (`retail.csv`) ingested using PySpark.
- Stored as Delta table: `bronze_daily_sales`.

### ğŸŸª Silver Layer
- Transformation:
  - Derived column: `revenue = quantity * price`.
- Stored as Delta table: `silver_daily_sales`.

### ğŸŸ¨ Gold Layer
- Business-ready enrichments:
  - ğŸ“ˆ Rolling 7-day average of quantity sold
  - âš ï¸ Low stock flag (`stock < 500`)
  - ğŸ’¸ Price tier classification:
    - Low: `< 1.10`
    - Medium: `1.10 - 1.20`
    - High: `> 1.20`
- Stored as Delta table: `gold_daily_sales`.

---

## ğŸ” Sample Business Insights

- Days with high revenue or demand
- Identifying dates/items triggering low-stock alerts
- Performance of products based on pricing tiers
- Trends in rolling average sales

---

## ğŸ“‚ Project Structure

